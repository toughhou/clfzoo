2019-06-16 21:54:15,056:INFO: process train file ../data/smp2019_ecdt/SMP2019.train
2019-06-16 21:54:15,080:INFO: process dev file ../data/smp2019_ecdt/SMP2019.test
2019-06-16 21:54:15,169:INFO: Preprocesing...
2019-06-16 21:54:15,251:INFO: After filter 1881 tokens, the final vocab size is 438
2019-06-16 21:54:15,252:INFO: Assigning embeddings...
2019-06-16 21:54:15,254:INFO: Saving vocab...
2019-06-16 21:54:15,266:INFO: ====== Done with preparing! ======
2019-06-16 21:54:15,267:INFO: Init model...
2019-06-16 21:54:16,139:INFO: Init session
2019-06-16 21:54:17,826:INFO: Convert text to id
2019-06-16 21:54:17,876:INFO: Start to train
2019-06-16 21:54:18,278:INFO: ########################################
2019-06-16 21:54:18,278:INFO: Epoch 1 / 50
2019-06-16 21:54:20,052:INFO: 2019-06-16 21:54:20	 batch 1   to 1  :	global_step 0    	loss 3.3042	acc 0.0938
2019-06-16 21:54:20,145:INFO: 2019-06-16 21:54:20	 batch 2   to 2  :	global_step 0    	loss 3.2762	acc 0.0625
2019-06-16 21:54:20,236:INFO: 2019-06-16 21:54:20	 batch 3   to 3  :	global_step 0    	loss 3.0778	acc 0.2188
2019-06-16 21:54:20,331:INFO: 2019-06-16 21:54:20	 batch 4   to 4  :	global_step 0    	loss 3.0694	acc 0.1406
2019-06-16 21:54:20,423:INFO: 2019-06-16 21:54:20	 batch 5   to 5  :	global_step 0    	loss 3.0616	acc 0.2031
2019-06-16 21:54:20,517:INFO: 2019-06-16 21:54:20	 batch 6   to 6  :	global_step 0    	loss 3.0078	acc 0.2031
2019-06-16 21:54:20,611:INFO: 2019-06-16 21:54:20	 batch 7   to 7  :	global_step 0    	loss 3.0654	acc 0.1719
2019-06-16 21:54:20,704:INFO: 2019-06-16 21:54:20	 batch 8   to 8  :	global_step 0    	loss 2.9830	acc 0.1406
2019-06-16 21:54:20,798:INFO: 2019-06-16 21:54:20	 batch 9   to 9  :	global_step 0    	loss 3.2157	acc 0.1562
2019-06-16 21:54:20,892:INFO: 2019-06-16 21:54:20	 batch 10  to 10 :	global_step 0    	loss 2.8706	acc 0.2344
2019-06-16 21:54:20,983:INFO: 2019-06-16 21:54:20	 batch 11  to 11 :	global_step 0    	loss 3.1443	acc 0.1250
2019-06-16 21:54:21,077:INFO: 2019-06-16 21:54:21	 batch 12  to 12 :	global_step 0    	loss 2.8876	acc 0.2031
2019-06-16 21:54:21,173:INFO: 2019-06-16 21:54:21	 batch 13  to 13 :	global_step 0    	loss 3.0381	acc 0.1719
2019-06-16 21:54:21,270:INFO: 2019-06-16 21:54:21	 batch 14  to 14 :	global_step 0    	loss 2.9062	acc 0.2031
2019-06-16 21:54:21,376:INFO: 2019-06-16 21:54:21	 batch 15  to 15 :	global_step 0    	loss 3.0316	acc 0.1562
2019-06-16 21:54:21,476:INFO: 2019-06-16 21:54:21	 batch 16  to 16 :	global_step 0    	loss 2.8961	acc 0.2188
2019-06-16 21:54:21,577:INFO: 2019-06-16 21:54:21	 batch 17  to 17 :	global_step 0    	loss 3.0856	acc 0.1250
2019-06-16 21:54:21,674:INFO: 2019-06-16 21:54:21	 batch 18  to 18 :	global_step 0    	loss 3.0703	acc 0.1094
2019-06-16 21:54:21,770:INFO: 2019-06-16 21:54:21	 batch 19  to 19 :	global_step 0    	loss 2.9565	acc 0.1562
2019-06-16 21:54:21,865:INFO: 2019-06-16 21:54:21	 batch 20  to 20 :	global_step 0    	loss 3.0582	acc 0.1562
2019-06-16 21:54:21,957:INFO: 2019-06-16 21:54:21	 batch 21  to 21 :	global_step 0    	loss 3.0055	acc 0.1562
2019-06-16 21:54:22,049:INFO: 2019-06-16 21:54:22	 batch 22  to 22 :	global_step 0    	loss 2.9194	acc 0.1875
