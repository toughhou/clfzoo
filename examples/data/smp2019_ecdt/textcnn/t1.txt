C:\envs\tf-1.10\python.exe C:/code/challenge/clfzoo/examples/textcnn/train.py
process train file ../data/smp2019_ecdt/SMP2019.train
process dev file ../data/smp2019_ecdt/SMP2019.test
Preprocesing...
After filter 1881 tokens, the final vocab size is 438
Assigning embeddings...
Saving vocab...
====== Done with preparing! ======
Init model...
Init session
Convert text to id
Start to train
########################################
Epoch 1 / 50
2019-06-15 18:11:49	 batch 1 to 5:	loss 3.1475	acc 0.1281
2019-06-15 18:11:50	 batch 6 to 10:	loss 3.0336	acc 0.1594
2019-06-15 18:11:50	 batch 11 to 15:	loss 3.0149	acc 0.1906
2019-06-15 18:11:50	 batch 16 to 20:	loss 2.8791	acc 0.2156
2019-06-15 18:11:51	 batch 21 to 25:	loss 2.9511	acc 0.1938
C:\envs\tf-1.10\lib\site-packages\sklearn\metrics\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        20
           1       0.00      0.00      0.00        29
           2       0.00      0.00      0.00        31
           3       0.00      0.00      0.00         1
           4       0.00      0.00      0.00        25
           5       0.00      0.00      0.00        39
           6       0.00      0.00      0.00        27
           7       0.00      0.00      0.00         4
           8       0.00      0.00      0.00        30
           9       0.00      0.00      0.00        24
          10       0.00      0.00      0.00        11
          11       0.00      0.00      0.00         6
          12       0.00      0.00      0.00        13
          13       0.00      0.00      0.00         4
          14       0.00      0.00      0.00         9
          15       0.00      0.00      0.00        21
          16       0.00      0.00      0.00        29
          17       0.00      0.00      0.00        27
          18       0.00      0.00      0.00        12
          19       0.00      0.00      0.00        36
          20       0.21      0.98      0.35       131
          21       0.00      0.00      0.00        51
          22       0.00      0.00      0.00        16
          23       0.00      0.00      0.00        36
          24       0.00      0.00      0.00        29
          25       0.60      0.32      0.41        38
          26       0.33      0.64      0.43        74

    accuracy                           0.24       773
   macro avg       0.04      0.07      0.04       773
weighted avg       0.10      0.24      0.12       773

C:\envs\tf-1.10\lib\site-packages\sklearn\metrics\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
C:\envs\tf-1.10\lib\site-packages\sklearn\metrics\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-06-15 18:11:52	p 0.0423	acc 0.2419	f1 0.0444	r 0.0714
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 2 / 50
2019-06-15 18:11:52	 batch 1 to 5:	loss 2.7324	acc 0.2156
2019-06-15 18:11:53	 batch 6 to 10:	loss 2.5877	acc 0.2594
2019-06-15 18:11:53	 batch 11 to 15:	loss 2.4856	acc 0.3187
2019-06-15 18:11:54	 batch 16 to 20:	loss 2.3357	acc 0.4062
2019-06-15 18:11:54	 batch 21 to 25:	loss 2.2646	acc 0.4344
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        20
           1       1.00      0.72      0.84        29
           2       0.00      0.00      0.00        31
           3       0.00      0.00      0.00         1
           4       0.00      0.00      0.00        25
           5       0.50      0.31      0.38        39
           6       1.00      0.41      0.58        27
           7       0.00      0.00      0.00         4
           8       0.75      0.60      0.67        30
           9       0.72      0.54      0.62        24
          10       0.00      0.00      0.00        11
          11       0.00      0.00      0.00         6
          12       0.00      0.00      0.00        13
          13       0.00      0.00      0.00         4
          14       0.00      0.00      0.00         9
          15       0.00      0.00      0.00        21
          16       0.52      0.59      0.55        29
          17       0.00      0.00      0.00        27
          18       0.00      0.00      0.00        12
          19       0.00      0.00      0.00        36
          20       0.51      0.98      0.67       131
          21       0.72      0.51      0.60        51
          22       0.00      0.00      0.00        16
          23       0.83      0.94      0.88        36
          24       0.00      0.00      0.00        29
          25       0.76      0.84      0.80        38
          26       0.25      0.92      0.40        74

    accuracy                           0.49       773
   macro avg       0.28      0.27      0.26       773
weighted avg       0.40      0.49      0.41       773

2019-06-15 18:11:55	p 0.2801	acc 0.4929	f1 0.2586	r 0.2729
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 3 / 50
2019-06-15 18:11:56	 batch 1 to 5:	loss 2.1322	acc 0.4219
2019-06-15 18:11:56	 batch 6 to 10:	loss 1.8877	acc 0.5437
2019-06-15 18:11:57	 batch 11 to 15:	loss 1.7640	acc 0.5062
2019-06-15 18:11:57	 batch 16 to 20:	loss 1.8197	acc 0.5344
2019-06-15 18:11:58	 batch 21 to 25:	loss 1.6979	acc 0.5500
              precision    recall  f1-score   support

           0       0.32      0.40      0.36        20
           1       0.45      0.97      0.62        29
           2       0.56      0.16      0.25        31
           3       0.00      0.00      0.00         1
           4       0.33      0.08      0.13        25
           5       0.43      0.67      0.53        39
           6       0.95      0.74      0.83        27
           7       0.00      0.00      0.00         4
           8       1.00      0.97      0.98        30
           9       0.47      0.71      0.57        24
          10       0.00      0.00      0.00        11
          11       0.00      0.00      0.00         6
          12       0.00      0.00      0.00        13
          13       0.00      0.00      0.00         4
          14       0.00      0.00      0.00         9
          15       0.00      0.00      0.00        21
          16       0.55      0.59      0.57        29
          17       0.33      0.04      0.07        27
          18       0.00      0.00      0.00        12
          19       0.71      0.14      0.23        36
          20       0.62      0.98      0.76       131
          21       0.60      0.55      0.57        51
          22       1.00      0.12      0.22        16
          23       0.69      0.94      0.80        36
          24       0.00      0.00      0.00        29
          25       0.95      0.55      0.70        38
          26       0.38      0.81      0.52        74

    accuracy                           0.56       773
   macro avg       0.38      0.35      0.32       773
weighted avg       0.51      0.56      0.48       773

2019-06-15 18:11:58	p 0.3837	acc 0.5576	f1 0.3220	r 0.3485
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 4 / 50
2019-06-15 18:11:59	 batch 1 to 5:	loss 1.3699	acc 0.6344
2019-06-15 18:11:59	 batch 6 to 10:	loss 1.4386	acc 0.6250
2019-06-15 18:12:00	 batch 11 to 15:	loss 1.4339	acc 0.5875
2019-06-15 18:12:00	 batch 16 to 20:	loss 1.2907	acc 0.6438
2019-06-15 18:12:01	 batch 21 to 25:	loss 1.2773	acc 0.6500
              precision    recall  f1-score   support

           0       0.27      0.20      0.23        20
           1       0.90      0.97      0.93        29
           2       0.65      0.35      0.46        31
           3       0.00      0.00      0.00         1
           4       0.28      0.48      0.35        25
           5       0.65      0.28      0.39        39
           6       0.95      0.70      0.81        27
           7       0.00      0.00      0.00         4
           8       1.00      0.93      0.97        30
           9       0.71      0.62      0.67        24
          10       1.00      0.27      0.43        11
          11       0.00      0.00      0.00         6
          12       0.00      0.00      0.00        13
          13       0.00      0.00      0.00         4
          14       0.00      0.00      0.00         9
          15       0.00      0.00      0.00        21
          16       1.00      0.59      0.74        29
          17       0.39      0.26      0.31        27
          18       0.67      0.17      0.27        12
          19       0.96      0.67      0.79        36
          20       0.84      0.93      0.88       131
          21       0.25      0.90      0.40        51
          22       0.86      0.38      0.52        16
          23       0.69      0.97      0.80        36
          24       0.85      0.38      0.52        29
          25       0.86      0.79      0.82        38
          26       0.48      0.53      0.50        74

    accuracy                           0.61       773
   macro avg       0.53      0.42      0.44       773
weighted avg       0.65      0.61      0.59       773

2019-06-15 18:12:01	p 0.5272	acc 0.6080	f1 0.4366	r 0.4212
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 5 / 50
2019-06-15 18:12:02	 batch 1 to 5:	loss 1.1914	acc 0.6719
2019-06-15 18:12:02	 batch 6 to 10:	loss 1.1954	acc 0.7094
2019-06-15 18:12:03	 batch 11 to 15:	loss 1.0960	acc 0.7031
2019-06-15 18:12:03	 batch 16 to 20:	loss 0.8948	acc 0.7875
2019-06-15 18:12:04	 batch 21 to 25:	loss 1.0154	acc 0.7406
              precision    recall  f1-score   support

           0       0.27      0.40      0.32        20
           1       1.00      0.93      0.96        29
           2       0.35      0.58      0.43        31
           3       0.00      0.00      0.00         1
           4       0.43      0.48      0.45        25
           5       0.74      0.74      0.74        39
           6       0.86      0.93      0.89        27
           7       0.00      0.00      0.00         4
           8       1.00      0.93      0.97        30
           9       0.81      0.71      0.76        24
          10       1.00      0.64      0.78        11
          11       1.00      0.17      0.29         6
          12       0.00      0.00      0.00        13
          13       0.00      0.00      0.00         4
          14       0.00      0.00      0.00         9
          15       0.00      0.00      0.00        21
          16       0.94      0.59      0.72        29
          17       0.36      0.15      0.21        27
          18       0.80      0.33      0.47        12
          19       0.87      0.72      0.79        36
          20       0.93      0.89      0.91       131
          21       0.45      0.90      0.60        51
          22       0.69      0.56      0.62        16
          23       0.92      1.00      0.96        36
          24       0.88      0.48      0.62        29
          25       0.80      0.95      0.87        38
          26       0.45      0.65      0.53        74

    accuracy                           0.68       773
   macro avg       0.58      0.51      0.51       773
weighted avg       0.69      0.68      0.67       773

2019-06-15 18:12:04	p 0.5761	acc 0.6843	f1 0.5148	r 0.5086
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 6 / 50
2019-06-15 18:12:05	 batch 1 to 5:	loss 0.8233	acc 0.8000
2019-06-15 18:12:05	 batch 6 to 10:	loss 0.9265	acc 0.7594
2019-06-15 18:12:06	 batch 11 to 15:	loss 0.8760	acc 0.7750
2019-06-15 18:12:06	 batch 16 to 20:	loss 0.8928	acc 0.7781
2019-06-15 18:12:07	 batch 21 to 25:	loss 0.7905	acc 0.7750
              precision    recall  f1-score   support

           0       0.28      0.65      0.39        20
           1       0.53      0.97      0.68        29
           2       0.74      0.45      0.56        31
           3       0.00      0.00      0.00         1
           4       0.55      0.44      0.49        25
           5       0.81      0.67      0.73        39
           6       1.00      0.93      0.96        27
           7       0.00      0.00      0.00         4
           8       1.00      0.97      0.98        30
           9       0.56      0.92      0.70        24
          10       1.00      0.73      0.84        11
          11       1.00      0.50      0.67         6
          12       1.00      0.31      0.47        13
          13       1.00      0.25      0.40         4
          14       0.00      0.00      0.00         9
          15       1.00      0.05      0.09        21
          16       0.83      0.66      0.73        29
          17       0.50      0.15      0.23        27
          18       0.29      0.33      0.31        12
          19       0.73      0.92      0.81        36
          20       0.88      0.94      0.91       131
          21       0.56      0.88      0.68        51
          22       0.76      0.81      0.79        16
          23       0.90      0.97      0.93        36
          24       0.82      0.48      0.61        29
          25       0.84      0.95      0.89        38
          26       0.58      0.51      0.54        74

    accuracy                           0.71       773
   macro avg       0.67      0.57      0.57       773
weighted avg       0.74      0.71      0.69       773

2019-06-15 18:12:08	p 0.6723	acc 0.7102	f1 0.5705	r 0.5711
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 7 / 50
2019-06-15 18:12:08	 batch 1 to 5:	loss 0.7327	acc 0.8219
2019-06-15 18:12:08	 batch 6 to 10:	loss 0.7980	acc 0.7906
2019-06-15 18:12:09	 batch 11 to 15:	loss 0.6317	acc 0.8562
2019-06-15 18:12:09	 batch 16 to 20:	loss 0.7700	acc 0.8344
2019-06-15 18:12:10	 batch 21 to 25:	loss 0.6632	acc 0.8156
              precision    recall  f1-score   support

           0       0.32      0.55      0.41        20
           1       0.79      0.93      0.86        29
           2       0.70      0.68      0.69        31
           3       0.00      0.00      0.00         1
           4       0.30      0.60      0.40        25
           5       0.77      0.77      0.77        39
           6       0.93      1.00      0.96        27
           7       0.00      0.00      0.00         4
           8       1.00      0.97      0.98        30
           9       0.92      0.92      0.92        24
          10       1.00      0.82      0.90        11
          11       0.36      0.67      0.47         6
          12       0.67      0.46      0.55        13
          13       1.00      0.50      0.67         4
          14       0.00      0.00      0.00         9
          15       0.92      0.52      0.67        21
          16       0.91      0.69      0.78        29
          17       0.47      0.26      0.33        27
          18       0.62      0.42      0.50        12
          19       0.69      0.94      0.80        36
          20       0.90      0.92      0.91       131
          21       0.82      0.78      0.80        51
          22       0.79      0.94      0.86        16
          23       0.92      1.00      0.96        36
          24       0.81      0.45      0.58        29
          25       0.92      0.89      0.91        38
          26       0.59      0.59      0.59        74

    accuracy                           0.75       773
   macro avg       0.67      0.64      0.64       773
weighted avg       0.76      0.75      0.75       773

2019-06-15 18:12:11	p 0.6716	acc 0.7529	f1 0.6392	r 0.6395
########################################
Epoch 8 / 50
2019-06-15 18:12:11	 batch 1 to 5:	loss 0.6894	acc 0.8125
2019-06-15 18:12:12	 batch 6 to 10:	loss 0.5824	acc 0.8688
2019-06-15 18:12:12	 batch 11 to 15:	loss 0.6168	acc 0.8281
2019-06-15 18:12:12	 batch 16 to 20:	loss 0.5668	acc 0.8625
2019-06-15 18:12:13	 batch 21 to 25:	loss 0.6222	acc 0.8375
              precision    recall  f1-score   support

           0       0.35      0.60      0.44        20
           1       0.97      0.97      0.97        29
           2       0.90      0.61      0.73        31
           3       0.00      0.00      0.00         1
           4       0.53      0.32      0.40        25
           5       0.83      0.77      0.80        39
           6       0.90      0.96      0.93        27
           7       0.00      0.00      0.00         4
           8       1.00      0.97      0.98        30
           9       0.85      0.92      0.88        24
          10       1.00      1.00      1.00        11
          11       0.83      0.83      0.83         6
          12       0.71      0.38      0.50        13
          13       1.00      0.25      0.40         4
          14       1.00      0.33      0.50         9
          15       1.00      0.48      0.65        21
          16       0.96      0.79      0.87        29
          17       0.53      0.30      0.38        27
          18       0.46      0.50      0.48        12
          19       0.85      0.92      0.88        36
          20       0.79      0.98      0.88       131
          21       0.88      0.84      0.86        51
          22       0.78      0.88      0.82        16
          23       0.97      1.00      0.99        36
          24       0.94      0.52      0.67        29
          25       0.95      0.95      0.95        38
          26       0.51      0.72      0.60        74

    accuracy                           0.78       773
   macro avg       0.76      0.66      0.68       773
weighted avg       0.80      0.78      0.77       773

2019-06-15 18:12:14	p 0.7590	acc 0.7827	f1 0.6806	r 0.6586
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 9 / 50
2019-06-15 18:12:14	 batch 1 to 5:	loss 0.5533	acc 0.8656
2019-06-15 18:12:15	 batch 6 to 10:	loss 0.5236	acc 0.8625
2019-06-15 18:12:15	 batch 11 to 15:	loss 0.4466	acc 0.8781
2019-06-15 18:12:16	 batch 16 to 20:	loss 0.5233	acc 0.8688
2019-06-15 18:12:16	 batch 21 to 25:	loss 0.4834	acc 0.8875
              precision    recall  f1-score   support

           0       0.29      0.75      0.42        20
           1       1.00      0.93      0.96        29
           2       0.83      0.65      0.73        31
           3       0.00      0.00      0.00         1
           4       0.65      0.44      0.52        25
           5       0.89      0.82      0.85        39
           6       0.96      1.00      0.98        27
           7       0.00      0.00      0.00         4
           8       1.00      1.00      1.00        30
           9       1.00      0.88      0.93        24
          10       0.92      1.00      0.96        11
          11       1.00      0.83      0.91         6
          12       0.78      0.54      0.64        13
          13       1.00      0.25      0.40         4
          14       1.00      0.22      0.36         9
          15       1.00      0.43      0.60        21
          16       0.96      0.90      0.93        29
          17       0.46      0.22      0.30        27
          18       1.00      0.50      0.67        12
          19       0.86      0.86      0.86        36
          20       0.95      0.92      0.93       131
          21       0.71      0.88      0.79        51
          22       0.82      0.88      0.85        16
          23       1.00      1.00      1.00        36
          24       0.85      0.59      0.69        29
          25       0.84      1.00      0.92        38
          26       0.50      0.74      0.60        74

    accuracy                           0.79       773
   macro avg       0.79      0.67      0.70       773
weighted avg       0.83      0.79      0.79       773

2019-06-15 18:12:17	p 0.7883	acc 0.7930	f1 0.6966	r 0.6750
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 10 / 50
2019-06-15 18:12:17	 batch 1 to 5:	loss 0.4134	acc 0.9062
2019-06-15 18:12:18	 batch 6 to 10:	loss 0.4359	acc 0.9031
2019-06-15 18:12:18	 batch 11 to 15:	loss 0.4065	acc 0.9094
2019-06-15 18:12:19	 batch 16 to 20:	loss 0.4708	acc 0.8812
2019-06-15 18:12:19	 batch 21 to 25:	loss 0.3353	acc 0.9094
              precision    recall  f1-score   support

           0       0.50      0.70      0.58        20
           1       0.85      0.97      0.90        29
           2       0.61      0.74      0.67        31
           3       0.00      0.00      0.00         1
           4       0.69      0.36      0.47        25
           5       0.84      0.79      0.82        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      0.97      0.98        30
           9       0.92      0.96      0.94        24
          10       1.00      0.82      0.90        11
          11       0.83      0.83      0.83         6
          12       0.78      0.54      0.64        13
          13       1.00      0.50      0.67         4
          14       1.00      0.33      0.50         9
          15       1.00      0.90      0.95        21
          16       1.00      0.86      0.93        29
          17       0.58      0.52      0.55        27
          18       0.50      0.67      0.57        12
          19       0.82      0.89      0.85        36
          20       0.89      0.95      0.92       131
          21       0.79      0.90      0.84        51
          22       0.83      0.94      0.88        16
          23       0.92      1.00      0.96        36
          24       0.80      0.55      0.65        29
          25       0.95      0.97      0.96        38
          26       0.63      0.65      0.64        74

    accuracy                           0.82       773
   macro avg       0.77      0.72      0.73       773
weighted avg       0.82      0.82      0.81       773

2019-06-15 18:12:20	p 0.7680	acc 0.8163	f1 0.7263	r 0.7155
########################################
Epoch 11 / 50
2019-06-15 18:12:20	 batch 1 to 5:	loss 0.3361	acc 0.9313
2019-06-15 18:12:21	 batch 6 to 10:	loss 0.3069	acc 0.9344
2019-06-15 18:12:21	 batch 11 to 15:	loss 0.3452	acc 0.9187
2019-06-15 18:12:22	 batch 16 to 20:	loss 0.3544	acc 0.9250
2019-06-15 18:12:22	 batch 21 to 25:	loss 0.3996	acc 0.8938
              precision    recall  f1-score   support

           0       0.31      0.80      0.45        20
           1       1.00      0.97      0.98        29
           2       0.95      0.61      0.75        31
           3       0.00      0.00      0.00         1
           4       0.43      0.64      0.52        25
           5       0.88      0.72      0.79        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      1.00      1.00        30
           9       1.00      0.88      0.93        24
          10       0.85      1.00      0.92        11
          11       0.83      0.83      0.83         6
          12       0.90      0.69      0.78        13
          13       1.00      0.50      0.67         4
          14       1.00      0.56      0.71         9
          15       1.00      0.86      0.92        21
          16       0.97      0.97      0.97        29
          17       0.47      0.30      0.36        27
          18       1.00      0.50      0.67        12
          19       0.86      0.89      0.88        36
          20       0.88      0.97      0.92       131
          21       0.84      0.92      0.88        51
          22       0.80      1.00      0.89        16
          23       0.97      1.00      0.99        36
          24       0.86      0.66      0.75        29
          25       1.00      0.95      0.97        38
          26       0.61      0.57      0.59        74

    accuracy                           0.82       773
   macro avg       0.79      0.73      0.74       773
weighted avg       0.84      0.82      0.82       773

2019-06-15 18:12:23	p 0.7933	acc 0.8176	f1 0.7448	r 0.7319
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 12 / 50
2019-06-15 18:12:24	 batch 1 to 5:	loss 0.3296	acc 0.9375
2019-06-15 18:12:24	 batch 6 to 10:	loss 0.2932	acc 0.9375
2019-06-15 18:12:24	 batch 11 to 15:	loss 0.2532	acc 0.9437
2019-06-15 18:12:25	 batch 16 to 20:	loss 0.3032	acc 0.9313
2019-06-15 18:12:25	 batch 21 to 25:	loss 0.3099	acc 0.9250
              precision    recall  f1-score   support

           0       0.47      0.70      0.56        20
           1       1.00      0.97      0.98        29
           2       0.84      0.68      0.75        31
           3       0.00      0.00      0.00         1
           4       0.72      0.52      0.60        25
           5       0.86      0.82      0.84        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      0.97      0.98        30
           9       0.92      0.92      0.92        24
          10       1.00      0.82      0.90        11
          11       0.83      0.83      0.83         6
          12       1.00      0.62      0.76        13
          13       1.00      0.50      0.67         4
          14       1.00      0.56      0.71         9
          15       1.00      0.67      0.80        21
          16       0.97      0.97      0.97        29
          17       0.48      0.56      0.52        27
          18       0.77      0.83      0.80        12
          19       0.91      0.89      0.90        36
          20       0.88      0.97      0.92       131
          21       0.87      0.88      0.87        51
          22       0.82      0.88      0.85        16
          23       0.92      1.00      0.96        36
          24       0.89      0.59      0.71        29
          25       0.97      0.95      0.96        38
          26       0.60      0.76      0.67        74

    accuracy                           0.83       773
   macro avg       0.80      0.73      0.76       773
weighted avg       0.85      0.83      0.83       773

2019-06-15 18:12:26	p 0.8047	acc 0.8344	f1 0.7569	r 0.7339
Model saved in ./models/textcnn/ckpt, with name textcnn.
New best score!

########################################
Epoch 13 / 50
2019-06-15 18:12:27	 batch 1 to 5:	loss 0.2914	acc 0.9313
2019-06-15 18:12:27	 batch 6 to 10:	loss 0.2703	acc 0.9344
2019-06-15 18:12:28	 batch 11 to 15:	loss 0.2350	acc 0.9469
2019-06-15 18:12:28	 batch 16 to 20:	loss 0.2411	acc 0.9594
2019-06-15 18:12:29	 batch 21 to 25:	loss 0.2859	acc 0.9406
              precision    recall  f1-score   support

           0       0.62      0.65      0.63        20
           1       0.97      0.97      0.97        29
           2       0.92      0.77      0.84        31
           3       0.00      0.00      0.00         1
           4       0.63      0.48      0.55        25
           5       0.60      0.90      0.72        39
           6       0.93      1.00      0.96        27
           7       0.00      0.00      0.00         4
           8       1.00      0.97      0.98        30
           9       0.92      0.92      0.92        24
          10       1.00      0.82      0.90        11
          11       0.62      0.83      0.71         6
          12       0.82      0.69      0.75        13
          13       0.67      0.50      0.57         4
          14       1.00      0.67      0.80         9
          15       1.00      0.86      0.92        21
          16       1.00      0.83      0.91        29
          17       0.63      0.63      0.63        27
          18       0.77      0.83      0.80        12
          19       0.91      0.83      0.87        36
          20       0.86      0.97      0.91       131
          21       0.92      0.88      0.90        51
          22       0.84      1.00      0.91        16
          23       0.95      1.00      0.97        36
          24       0.79      0.66      0.72        29
          25       1.00      0.95      0.97        38
          26       0.66      0.65      0.65        74

    accuracy                           0.84       773
   macro avg       0.78      0.75      0.76       773
weighted avg       0.84      0.84      0.83       773

2019-06-15 18:12:30	p 0.7789	acc 0.8370	f1 0.7585	r 0.7498
########################################
Epoch 14 / 50
2019-06-15 18:12:30	 batch 1 to 5:	loss 0.2185	acc 0.9469
2019-06-15 18:12:30	 batch 6 to 10:	loss 0.2547	acc 0.9531
2019-06-15 18:12:31	 batch 11 to 15:	loss 0.2084	acc 0.9500
2019-06-15 18:12:31	 batch 16 to 20:	loss 0.2329	acc 0.9594
2019-06-15 18:12:32	 batch 21 to 25:	loss 0.2077	acc 0.9563
              precision    recall  f1-score   support

           0       0.61      0.70      0.65        20
           1       0.90      0.97      0.93        29
           2       0.96      0.71      0.81        31
           3       0.00      0.00      0.00         1
           4       1.00      0.64      0.78        25
           5       0.94      0.74      0.83        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      0.97      0.98        30
           9       0.79      0.92      0.85        24
          10       1.00      0.82      0.90        11
          11       0.80      0.67      0.73         6
          12       0.69      0.69      0.69        13
          13       1.00      0.50      0.67         4
          14       0.89      0.89      0.89         9
          15       1.00      0.76      0.86        21
          16       1.00      0.86      0.93        29
          17       0.63      0.63      0.63        27
          18       0.43      0.83      0.57        12
          19       0.82      0.89      0.85        36
          20       0.88      0.99      0.94       131
          21       0.94      0.88      0.91        51
          22       0.75      0.38      0.50        16
          23       0.92      1.00      0.96        36
          24       0.86      0.62      0.72        29
          25       0.97      0.97      0.97        38
          26       0.54      0.70      0.61        74

    accuracy                           0.83       773
   macro avg       0.79      0.73      0.75       773
weighted avg       0.85      0.83      0.83       773

2019-06-15 18:12:33	p 0.7897	acc 0.8318	f1 0.7470	r 0.7308
########################################
Epoch 15 / 50
2019-06-15 18:12:33	 batch 1 to 5:	loss 0.1857	acc 0.9531
2019-06-15 18:12:34	 batch 6 to 10:	loss 0.1638	acc 0.9688
2019-06-15 18:12:34	 batch 11 to 15:	loss 0.1530	acc 0.9719
2019-06-15 18:12:34	 batch 16 to 20:	loss 0.2317	acc 0.9500
2019-06-15 18:12:35	 batch 21 to 25:	loss 0.2122	acc 0.9531
2019-06-15 18:12:36	p 0.7670	acc 0.8176	f1 0.7393	r 0.7317
########################################
Epoch 16 / 50
              precision    recall  f1-score   support

           0       0.58      0.70      0.64        20
           1       0.80      0.97      0.88        29
           2       0.95      0.65      0.77        31
           3       0.00      0.00      0.00         1
           4       0.62      0.52      0.57        25
           5       0.49      0.95      0.65        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       0.97      0.97      0.97        30
           9       0.81      0.92      0.86        24
          10       1.00      0.91      0.95        11
          11       0.71      0.83      0.77         6
          12       0.90      0.69      0.78        13
          13       0.33      0.50      0.40         4
          14       1.00      0.67      0.80         9
          15       1.00      0.81      0.89        21
          16       1.00      0.86      0.93        29
          17       0.59      0.63      0.61        27
          18       0.82      0.75      0.78        12
          19       0.94      0.83      0.88        36
          20       0.91      0.95      0.93       131
          21       0.90      0.92      0.91        51
          22       1.00      0.62      0.77        16
          23       0.95      1.00      0.97        36
          24       0.75      0.72      0.74        29
          25       1.00      0.82      0.90        38
          26       0.68      0.57      0.62        74

    accuracy                           0.82       773
   macro avg       0.77      0.73      0.74       773
weighted avg       0.84      0.82      0.82       773

2019-06-15 18:12:36	 batch 1 to 5:	loss 0.1795	acc 0.9688
2019-06-15 18:12:37	 batch 6 to 10:	loss 0.1805	acc 0.9594
2019-06-15 18:12:37	 batch 11 to 15:	loss 0.1791	acc 0.9594
2019-06-15 18:12:38	 batch 16 to 20:	loss 0.1639	acc 0.9625
2019-06-15 18:12:38	 batch 21 to 25:	loss 0.1370	acc 0.9844
              precision    recall  f1-score   support

           0       0.50      0.70      0.58        20
           1       0.88      0.97      0.92        29
           2       0.88      0.74      0.81        31
           3       0.00      0.00      0.00         1
           4       0.71      0.60      0.65        25
           5       0.78      0.90      0.83        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      1.00      1.00        30
           9       0.81      0.92      0.86        24
          10       1.00      1.00      1.00        11
          11       0.83      0.83      0.83         6
          12       1.00      0.69      0.82        13
          13       0.67      0.50      0.57         4
          14       0.86      0.67      0.75         9
          15       1.00      0.90      0.95        21
          16       1.00      0.93      0.96        29
          17       0.58      0.70      0.63        27
          18       0.82      0.75      0.78        12
          19       0.91      0.89      0.90        36
          20       0.92      0.95      0.94       131
          21       0.88      0.90      0.89        51
          22       0.92      0.75      0.83        16
          23       0.97      1.00      0.99        36
          24       0.75      0.72      0.74        29
          25       1.00      0.95      0.97        38
          26       0.62      0.62      0.62        74

    accuracy                           0.85       773
   macro avg       0.79      0.76      0.77       773
weighted avg       0.85      0.85      0.85       773

2019-06-15 18:12:39	p 0.7890	acc 0.8473	f1 0.7717	r 0.7626
########################################
Epoch 17 / 50
2019-06-15 18:12:39	 batch 1 to 5:	loss 0.1723	acc 0.9563
2019-06-15 18:12:40	 batch 6 to 10:	loss 0.1022	acc 0.9812
2019-06-15 18:12:40	 batch 11 to 15:	loss 0.1434	acc 0.9719
2019-06-15 18:12:41	 batch 16 to 20:	loss 0.1373	acc 0.9719
2019-06-15 18:12:41	 batch 21 to 25:	loss 0.1348	acc 0.9812
              precision    recall  f1-score   support

           0       0.54      0.70      0.61        20
           1       1.00      0.97      0.98        29
           2       0.57      0.81      0.67        31
           3       0.00      0.00      0.00         1
           4       0.74      0.68      0.71        25
           5       0.94      0.79      0.86        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      1.00      1.00        30
           9       0.92      0.92      0.92        24
          10       0.92      1.00      0.96        11
          11       0.83      0.83      0.83         6
          12       1.00      0.77      0.87        13
          13       0.67      0.50      0.57         4
          14       1.00      0.78      0.88         9
          15       1.00      0.71      0.83        21
          16       1.00      0.97      0.98        29
          17       0.55      0.67      0.60        27
          18       0.77      0.83      0.80        12
          19       0.94      0.89      0.91        36
          20       0.93      0.95      0.94       131
          21       0.86      0.84      0.85        51
          22       0.88      0.88      0.88        16
          23       0.95      1.00      0.97        36
          24       0.83      0.69      0.75        29
          25       1.00      0.92      0.96        38
          26       0.62      0.66      0.64        74

    accuracy                           0.85       773
   macro avg       0.79      0.77      0.78       773
weighted avg       0.86      0.85      0.85       773

2019-06-15 18:12:42	p 0.7942	acc 0.8461	f1 0.7769	r 0.7688
########################################
Epoch 18 / 50
2019-06-15 18:12:43	 batch 1 to 5:	loss 0.1422	acc 0.9781
2019-06-15 18:12:43	 batch 6 to 10:	loss 0.1002	acc 0.9844
2019-06-15 18:12:44	 batch 11 to 15:	loss 0.1173	acc 0.9781
2019-06-15 18:12:44	 batch 16 to 20:	loss 0.0946	acc 0.9875
2019-06-15 18:12:45	 batch 21 to 25:	loss 0.1241	acc 0.9781
2019-06-15 18:12:46	p 0.7855	acc 0.8473	f1 0.7805	r 0.7837
########################################
Epoch 19 / 50
              precision    recall  f1-score   support

           0       0.50      0.75      0.60        20
           1       0.85      0.97      0.90        29
           2       0.79      0.74      0.77        31
           3       0.00      0.00      0.00         1
           4       0.73      0.64      0.68        25
           5       0.87      0.85      0.86        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      1.00      1.00        30
           9       0.81      0.92      0.86        24
          10       0.92      1.00      0.96        11
          11       0.71      0.83      0.77         6
          12       1.00      0.69      0.82        13
          13       0.75      0.75      0.75         4
          14       1.00      0.78      0.88         9
          15       1.00      0.90      0.95        21
          16       1.00      0.97      0.98        29
          17       0.60      0.67      0.63        27
          18       0.71      0.83      0.77        12
          19       0.92      0.92      0.92        36
          20       0.90      0.96      0.93       131
          21       0.88      0.90      0.89        51
          22       0.89      1.00      0.94        16
          23       0.95      1.00      0.97        36
          24       0.78      0.62      0.69        29
          25       1.00      0.92      0.96        38
          26       0.64      0.55      0.59        74

    accuracy                           0.85       773
   macro avg       0.79      0.78      0.78       773
weighted avg       0.85      0.85      0.84       773

2019-06-15 18:12:46	 batch 1 to 5:	loss 0.0888	acc 0.9875
2019-06-15 18:12:47	 batch 6 to 10:	loss 0.0917	acc 0.9906
2019-06-15 18:12:47	 batch 11 to 15:	loss 0.1240	acc 0.9781
2019-06-15 18:12:47	 batch 16 to 20:	loss 0.0921	acc 0.9812
2019-06-15 18:12:48	 batch 21 to 25:	loss 0.1269	acc 0.9750
              precision    recall  f1-score   support

           0       0.48      0.70      0.57        20
           1       0.97      0.97      0.97        29
           2       0.73      0.77      0.75        31
           3       0.00      0.00      0.00         1
           4       0.59      0.68      0.63        25
           5       0.89      0.82      0.85        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       0.91      1.00      0.95        30
           9       0.92      0.92      0.92        24
          10       1.00      1.00      1.00        11
          11       0.83      0.83      0.83         6
          12       0.92      0.85      0.88        13
          13       0.50      0.75      0.60         4
          14       1.00      0.78      0.88         9
          15       0.90      0.90      0.90        21
          16       1.00      0.97      0.98        29
          17       0.75      0.44      0.56        27
          18       0.59      0.83      0.69        12
          19       0.94      0.86      0.90        36
          20       0.92      0.96      0.94       131
          21       0.92      0.88      0.90        51
          22       0.88      0.94      0.91        16
          23       0.95      1.00      0.97        36
          24       0.86      0.62      0.72        29
          25       1.00      0.92      0.96        38
          26       0.62      0.65      0.63        74

    accuracy                           0.85       773
   macro avg       0.78      0.78      0.77       773
weighted avg       0.85      0.85      0.84       773

2019-06-15 18:12:49	p 0.7796	acc 0.8461	f1 0.7738	r 0.7795
########################################
Epoch 20 / 50
2019-06-15 18:12:49	 batch 1 to 5:	loss 0.1262	acc 0.9719
2019-06-15 18:12:50	 batch 6 to 10:	loss 0.0715	acc 0.9938
2019-06-15 18:12:50	 batch 11 to 15:	loss 0.0827	acc 0.9875
2019-06-15 18:12:51	 batch 16 to 20:	loss 0.0876	acc 0.9906
2019-06-15 18:12:51	 batch 21 to 25:	loss 0.0844	acc 0.9844
              precision    recall  f1-score   support

           0       0.50      0.75      0.60        20
           1       0.97      0.97      0.97        29
           2       0.69      0.71      0.70        31
           3       0.00      0.00      0.00         1
           4       0.79      0.60      0.68        25
           5       1.00      0.79      0.89        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      1.00      1.00        30
           9       0.96      0.92      0.94        24
          10       0.92      1.00      0.96        11
          11       0.83      0.83      0.83         6
          12       0.71      0.77      0.74        13
          13       0.60      0.75      0.67         4
          14       1.00      0.78      0.88         9
          15       1.00      0.62      0.76        21
          16       1.00      0.93      0.96        29
          17       0.62      0.56      0.59        27
          18       0.67      0.83      0.74        12
          19       0.92      0.92      0.92        36
          20       0.92      0.96      0.94       131
          21       0.91      0.82      0.87        51
          22       0.88      0.94      0.91        16
          23       0.97      1.00      0.99        36
          24       0.83      0.66      0.73        29
          25       0.97      0.95      0.96        38
          26       0.60      0.77      0.67        74

    accuracy                           0.85       773
   macro avg       0.79      0.77      0.77       773
weighted avg       0.86      0.85      0.85       773

2019-06-15 18:12:52	p 0.7874	acc 0.8473	f1 0.7734	r 0.7711
########################################
Epoch 21 / 50
2019-06-15 18:12:52	 batch 1 to 5:	loss 0.0554	acc 1.0000
2019-06-15 18:12:53	 batch 6 to 10:	loss 0.0776	acc 0.9875
2019-06-15 18:12:53	 batch 11 to 15:	loss 0.1095	acc 0.9812
2019-06-15 18:12:54	 batch 16 to 20:	loss 0.0723	acc 0.9906
2019-06-15 18:12:54	 batch 21 to 25:	loss 0.0951	acc 0.9812
              precision    recall  f1-score   support

           0       0.48      0.70      0.57        20
           1       0.93      0.97      0.95        29
           2       0.76      0.81      0.78        31
           3       0.00      0.00      0.00         1
           4       0.80      0.64      0.71        25
           5       0.89      0.82      0.85        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       1.00      1.00      1.00        30
           9       0.88      0.92      0.90        24
          10       1.00      1.00      1.00        11
          11       0.83      0.83      0.83         6
          12       0.91      0.77      0.83        13
          13       0.60      0.75      0.67         4
          14       1.00      0.67      0.80         9
          15       0.90      0.90      0.90        21
          16       0.93      0.97      0.95        29
          17       0.63      0.63      0.63        27
          18       0.62      0.83      0.71        12
          19       0.94      0.92      0.93        36
          20       0.91      0.96      0.94       131
          21       0.90      0.90      0.90        51
          22       0.89      1.00      0.94        16
          23       0.97      1.00      0.99        36
          24       0.82      0.62      0.71        29
          25       1.00      0.95      0.97        38
          26       0.65      0.64      0.64        74

    accuracy                           0.86       773
   macro avg       0.79      0.78      0.78       773
weighted avg       0.86      0.86      0.85       773

2019-06-15 18:12:55	p 0.7877	acc 0.8551	f1 0.7820	r 0.7846
########################################
Epoch 22 / 50
2019-06-15 18:12:55	 batch 1 to 5:	loss 0.0938	acc 0.9812
2019-06-15 18:12:56	 batch 6 to 10:	loss 0.0589	acc 0.9938
2019-06-15 18:12:56	 batch 11 to 15:	loss 0.0566	acc 0.9906
2019-06-15 18:12:57	 batch 16 to 20:	loss 0.0595	acc 0.9906
2019-06-15 18:12:57	 batch 21 to 25:	loss 0.0603	acc 0.9938
              precision    recall  f1-score   support

           0       0.52      0.65      0.58        20
           1       0.97      0.97      0.97        29
           2       0.72      0.74      0.73        31
           3       0.00      0.00      0.00         1
           4       0.71      0.60      0.65        25
           5       0.89      0.85      0.87        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       0.97      0.97      0.97        30
           9       0.96      0.92      0.94        24
          10       1.00      1.00      1.00        11
          11       0.83      0.83      0.83         6
          12       0.77      0.77      0.77        13
          13       0.67      0.50      0.57         4
          14       1.00      0.78      0.88         9
          15       1.00      0.71      0.83        21
          16       1.00      0.93      0.96        29
          17       0.62      0.67      0.64        27
          18       0.67      0.83      0.74        12
          19       0.94      0.89      0.91        36
          20       0.89      0.96      0.92       131
          21       0.92      0.90      0.91        51
          22       0.92      0.75      0.83        16
          23       0.97      1.00      0.99        36
          24       0.83      0.66      0.73        29
          25       1.00      0.92      0.96        38
          26       0.60      0.72      0.65        74

    accuracy                           0.85       773
   macro avg       0.79      0.76      0.77       773
weighted avg       0.85      0.85      0.85       773

2019-06-15 18:12:58	p 0.7912	acc 0.8461	f1 0.7716	r 0.7595
########################################
Epoch 23 / 50
2019-06-15 18:12:59	 batch 1 to 5:	loss 0.0429	acc 0.9969
2019-06-15 18:12:59	 batch 6 to 10:	loss 0.0603	acc 0.9906
2019-06-15 18:12:59	 batch 11 to 15:	loss 0.0567	acc 0.9906
2019-06-15 18:13:00	 batch 16 to 20:	loss 0.0755	acc 0.9875
2019-06-15 18:13:00	 batch 21 to 25:	loss 0.0817	acc 0.9844
              precision    recall  f1-score   support

           0       0.58      0.70      0.64        20
           1       0.93      0.97      0.95        29
           2       0.88      0.68      0.76        31
           3       0.00      0.00      0.00         1
           4       0.70      0.64      0.67        25
           5       0.92      0.85      0.88        39
           6       1.00      1.00      1.00        27
           7       0.00      0.00      0.00         4
           8       0.97      1.00      0.98        30
           9       0.96      0.92      0.94        24
          10       0.92      1.00      0.96        11
          11       0.62      0.83      0.71         6
          12       0.92      0.85      0.88        13
          13       0.60      0.75      0.67         4
          14       1.00      0.78      0.88         9
          15       0.95      0.95      0.95        21
          16       1.00      0.97      0.98        29
          17       0.60      0.67      0.63        27
          18       0.62      0.83      0.71        12
          19       0.86      0.89      0.88        36
          20       0.90      0.98      0.94       131
          21       0.90      0.90      0.90        51
          22       0.89      1.00      0.94        16
          23       0.95      1.00      0.97        36
          24       0.95      0.62      0.75        29
          25       1.00      0.95      0.97        38
          26       0.66      0.66      0.66        74

    accuracy                           0.86       773
   macro avg       0.79      0.79      0.79       773
weighted avg       0.86      0.86      0.86       773

2019-06-15 18:13:01	p 0.7881	acc 0.8603	f1 0.7854	r 0.7914
Early stopping 11 epochs without improvement

Process finished with exit code 0
